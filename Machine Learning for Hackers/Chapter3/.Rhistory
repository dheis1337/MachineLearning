# is built by finding the first blank line in 'text', and getting each line after
# it. This is because each file is formatted as a blank line separating address informatino
# and the actual email sent. Finally, the connection is closed and the function returns
# a single element vector with the entire email content in it.
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break.
first.blank <- which(text == "")[1]
msg <- text[seq((first.blank + 1), length(text), by = 1)]
close(con)
return(paste(msg, collapse = " "))
}
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path, p, sep = "")))
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[spam.docs != "cmds"]
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path, p, sep = "")))
doc.corpus <- Corpus(VectorSource(all.spam))
doc.corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "coffee", "mug"))
return(corpus)
}
clean_corpus(doc.corpus)
?TermDocumentMatrix
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = 2)
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
make.tdm(all.spam)
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
doc.corpus <- termFreq(doc.corpus, control = list(stopwords = TRUE,
removePunctuation = TRUE, removeNumbers = TRUE,
bounds = 2))
doc.tdm <- TermDocumentMatrix(doc.corpus)
return(doc.tdm)
}
make.tdm(all.spam)
make.tdm <- function(doc.vec) {
doc.vec <- termFreq(doc.corpus, control = list(stopwords = TRUE,
removePunctuation = TRUE, removeNumbers = TRUE,
bounds = 2))
doc.corpus <- Corpus(VectorSource(doc.vec))
doc.tdm <- TermDocumentMatrix(doc.corpus)
return(doc.tdm)
}
make.tdm(all.spam)
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf)))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
make.tdm(all.spam)
spam.tdm <- make.tdm(all.spam)
spam.mat <- as.matrix(spam.tdm)
spam.mat[1:10, ]
spam.counts <- rowSums(spam.mat)
spam.counts
spam.df <- data.frame(cbind(names(spam.counts), as.numeric(spam.counts)),
stringsAsFactors = FALSE)
names(spam.df) <- c("term", "frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
1:nrow(spam.mat)
spam.occurrence <- sapply(1:nrow(spam.mat),
function(i) {length(which(spam.mat[i, ] > 0)) / ncol(spam.mat)})
spam.df
spam.density <- spam.df$frequency / sum(spam.df$frequency)
spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)
spam.df
spam.df[order(-spam.df$occurrence)]
spam.df[orderoccurrence)]
spam.df[order(occurrence)]
order(spam.df, -spam.df$occurrence)
head(spam.df)
?with
spam.df[with(spam.df, order(-occurrence))]
spam.df[with(spam.df, order(-occurrence)), ]
head(spam.df[with(spam.df, order(-occurrence)), ])
spam.df$term
spam.df[spam.df$term == "email"]
spam.df[spam.df$term == "email", ]
spam.df[spam.df$term == "html", ]
spam.df[spam.df$term == "body", ]
head(spam.df[with(spam.df, order(-occurrence)), ])
ham.docs <- dir(ham.path)
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[easyham.docs != "cmds"]
easyham.docs <- easyham.docs[1:500]
all.easy <- sapply(easyham.docs.docs, function(p) get.msg(paste(easyham.path.path, p, sep = "")))
all.easy <- sapply(easyham.docs, function(p) get.msg(paste(easyham.path.path, p, sep = "")))
all.easy <- sapply(easyham.docs, function(p) get.msg(paste(easyham.path, p, sep = "")))
easy.tdm <- make.tdm(all.easy)
easy.mat <- as.matrix(easy.tdm)
easy.counts <- rowSums(easy.mat)
easy.df <- data.frame(cbind(names(easy.counts), as.numeric(easy.counts)),
stringsAsFactors = FALSE)
names(easy.df) <- c("term", "frequency")
easy.df
easy.df$term
names(easy.df) <- c("term", "frequency")
easy.df$frequency <- as.numeric(easy.df$frequency)
easy.occurrence <- sapply(1:nrow(easy.mat),
function(i) {length(which(easy.mat[i, ] > 0)) / ncol(easy.mat)})
easy.density <- easy.df$frequency / sum(easy.df$frequency)
easy.df <- transform(easy.df, density = easy.density, occurrence = easy.occurrence)
head(easy.df[with(easy.df, order(-occurrence)), ])
?intersect
classify.email <- function(path, training.df, prior = .5, c = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq) - length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[hardham.docs != "cmds"]
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[hardham.docs != "cmds"]
hardham.spamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = easy.df))
hardham.hamtest
ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
hardham.hamtest
hardham.spamtest
easy.df
intersect(names(easy.counts), easy.df$term)
intersect(names(spam.counts), easy.df$term)
classify.email <- function(path, training.df, prior = .5, c = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior* c^(length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq) - length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[hardham.docs != "cmds"]
summary(hardham.res)
hardham.res
table(hardham.res)
easy.df
head(easy.df[with(easy.df, order(-occurrence)), ])
1e-6
1e-1
hardham.spamtest
install.packages("e1071")
library("e1071")
data(HouseVotes84)
data("Titanic")
data("Titanic")
Titanic
m <- naiveBayes(Survived ~., data = Titanic)
m
predict(m, as.data.frame(Titanic[, 1:3]))
predict(m, as.data.frame(Titanic)[, 1:3])
naiveBayes()
naiveBayes
naiveBayes()
naiveBayes(Survived ~., data = Titanic)
library(tm)
library(ggplot2)
setwd("C:/MyStuff/DataScience/Projects/MachineLearning/Machine Learning For Hackers/Chapter3")
spam.path <- "data/spam/"
spam.path2 <- "data/spam_2/"
easyham.path <- "data/easy_ham/"
easyham2.path <- "data/easy_ham_2/"
hardham.path <- "data/hard_ham/"
hardham2.path <- "data/hard_ham_2/"
# Next, we need to make a function to read in the emails.
get.msg <- function(path) {
# This function will be used in conjunction with an anonymous function and sapply
# shortly. First, the funciton opens a connection to each file under the "read as text"
# connection. Then it uses ReadLines and stores it into a vector. The 'msg' vector
# is a subset of 'text' vector which is the actual email portion. The 'msg' vector
# is built by finding the first blank line in 'text', and getting each line after
# it. This is because each file is formatted as a blank line separating address informatino
# and the actual email sent. Finally, the connection is closed and the function returns
# a single element vector with the entire email content in it.
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break.
first.blank <- which(text == "")[1]
msg <- text[seq((first.blank + 1), length(text), by = 1)]
close(con)
return(paste(msg, collapse = " "))
}
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[spam.docs != "cmds"]
spam.docs <- paste(spam.path, spam.docs, sep = "")
all.spam <- sapply(spam.docs, get.msg)
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf)))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf)))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
spam.tdm <- make.tdm(all.spam)
spam.mat <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.mat)
spam.counts
spam.df <- data.frame(cbind(names(spam.counts), as.numeric(spam.counts)),
stringsAsFactors = FALSE)
spam.df
head(spam.df)
spam.terms <- names(spam.counts)
spam.terms
spam.freq <- as.numeric(spam.counts)
spam.df <- data.table("Term" = spam.terms, "Frequency" = spam.counts)
library(data.table)
rm(spam.df)
spam.df <- data.table("Term" = spam.terms, "Frequency" = spam.counts)
spam.df
class(spam.df[Frequency])
class(spam.df[Frequency, ])
spam.df[Frequency]
class(spam.df)
spam.df[, Frequency]
class(spam.df[, Frequency])
head(spam.mat)
spam.counts
spam.counts / ncol(spam.mat)
spam.counts[1] / ncol(spam.mat)
spam.occurrence <- sapply(1:nrow(spam.mat),
function(i) {length(which(spam.mat[i, ] > 0)) / ncol(spam.mat)})
spam.occurrence[1]
spam.occurrence[111]
spam.counts[111] / ncol(spam.mat)
?transform
?grep
grep("[A-Z]+12")
grep("[A-Z]+12", spam.terms)
spam.density <- spam.df$frequency / sum(spam.df$frequency)
spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)
spam.df <- transform.data.table(spam.df, density = spam.density, occurrence = spam.occurrence)
?transform.data.table
spam.occurrence <- sapply(1:nrow(spam.mat),
function(i) {length(which(spam.mat[i, ] > 0)) / ncol(spam.mat)})
spam.density <- spam.df$frequency / sum(spam.df$frequency)
spam.df["Density" := spam.density]
spam.df[, "Density" := spam.density]
spam.df[, "Density" := list(spam.density)]
rm(spam.df)
spam.df <- data.frame(cbind(names(spam.counts), as.numeric(spam.counts)),
stringsAsFactors = FALSE)
names(spam.df) <- c("term", "frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.occurrence <- sapply(1:nrow(spam.mat),
function(i) {length(which(spam.mat[i, ] > 0)) / ncol(spam.mat)})
spam.density <- spam.df$frequency / sum(spam.df$frequency)
spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)), ])
spam.df <- as.data.table(spam.df)
head(spam.df)
head(spam.df[with(spam.df, order(-occurrence)), ])
?head
head(spam.df[with(spam.df, order(-occurrence)), ], n = 10)
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[easyham.docs != "cmds"]
easyham.docs <- easyham.docs[1:500]
all.easy <- sapply(easyham.docs, function(p) get.msg(paste(easyham.path, p, sep = "")))
easy.tdm <- make.tdm(all.easy)
easy.mat <- as.matrix(easy.tdm)
easy.counts <- rowSums(easy.mat)
easy.df <- data.frame(cbind(names(easy.counts), as.numeric(easy.counts)),
stringsAsFactors = FALSE)
names(easy.df) <- c("term", "frequency")
easy.df$frequency <- as.numeric(easy.df$frequency)
easy.occurrence <- sapply(1:nrow(easy.mat),
function(i) {length(which(easy.mat[i, ] > 0)) / ncol(easy.mat)})
easy.density <- easy.df$frequency / sum(easy.df$frequency)
easy.df <- transform(easy.df, density = easy.density, occurrence = easy.occurrence)
easy.df <- as.data.table(easy.df)
head(easy.df[with(easy.df, order(-occurrence)), ])
intersect(easy.df$term, spam.df$term)
easy.df
names(spam.mat)
names(spam.counts)
?prod
?match
spam.occurrence
classify.email <- function(path, training.df, prior = .5, c = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior * c^(length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[hardham.docs != "cmds"]
hardham.spamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = easy.df))
hardham.hamtest
hardham.spamtest
classify.email <- function(path, training.df, prior = .5, c = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior * c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = spam.df))
hardham.spamtest
classify.email <- function(path, training.df, prior = 0.5, c = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior * c ^ (length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep = ""),
training.df = spam.df))
hardham.spamtest
hardham.docs <- paste(hardham.path, hardham.docs, sep = "")
hardham.spamtest <- sapply(hardham.docs, classify.email, training.df = spam.df)
hardham.spamtest
hardham.spamtest <- sapply(hardham.docs, classify.email, training.df = spam.df, prior = .2)
hardham.hamtest <- sapply(hardham.docs, classify.email, training.df = easy.df, prior = .8)
hardham.spamtest
easy.df
spam.df
names(spam.df) == names(easy.df)
intersect(easy.df$term, spam.df$term)
classify.email <- function(path, training.df, prior = 0.5, d = 1e-6) {
msg <- get.msg(path)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior * d ^ (length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * d ^ (length(msg.freq) - length(msg.match)))
}
}
hardham.spamtest <- sapply(hardham.docs, classify.email, training.df = spam.df)
hardham.spamtest
hardham.docs
spam.df
test <- hardham.docs[1]
test
msg <- get.msg(test)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
head(msg.freq)
msg.freq
msg.tdm
as.matrix(msg.tdm)
test <- hardham.docs[2]
msg <- get.msg(test)
msg.tdm <- make.tdm(msg)
msg.tdm
test <- hardham.docs[3]
msg <- get.msg(test)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.freq
hardham.docs
ptest <- "C:\MyStuff\DataScience\Projects\MachineLearning\Machine Learning for Hackers\Chapter3\data"
"C:/MyStuff/DataScience/Projects/MachineLearning/Machine Learning for Hackers/Chapter3/data" == hardham.docs[1]
hardham.docs
hardham.docs[1]
msg
test <- hardham.docs[1]
msg <- get.msg(test)
msg
make.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf)))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
return(doc.tdm)
}
make.tdm(msg)
doc.corpus <- Corpus(VectorSource(msg))
doc.corpus
doc.corpus[1]
doc.corpus[[1]]
control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,
bounds = list(global = c(2, Inf)))
doc.tdm <- TermDocumentMatrix(doc.corpus, control)
doc.tdm
get.msg <- function(path) {
# This function will be used in conjunction with an anonymous function and sapply
# shortly. First, the funciton opens a connection to each file under the "read as text"
# connection. Then it uses ReadLines and stores it into a vector. The 'msg' vector
# is a subset of 'text' vector which is the actual email portion. The 'msg' vector
# is built by finding the first blank line in 'text', and getting each line after
# it. This is because each file is formatted as a blank line separating address informatino
# and the actual email sent. Finally, the connection is closed and the function returns
# a single element vector with the entire email content in it.
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break.
first.blank <- which(text == "")[1]
msg <- text[seq((first.blank + 1), length(text), by = 1)]
close(con)
return(paste(msg, collapse = "\n"))
}
msg <- get.msg(test)
msg
get.msg <- function(path) {
# This function will be used in conjunction with an anonymous function and sapply
# shortly. First, the funciton opens a connection to each file under the "read as text"
# connection. Then it uses ReadLines and stores it into a vector. The 'msg' vector
# is a subset of 'text' vector which is the actual email portion. The 'msg' vector
# is built by finding the first blank line in 'text', and getting each line after
# it. This is because each file is formatted as a blank line separating address informatino
# and the actual email sent. Finally, the connection is closed and the function returns
# a single element vector with the entire email content in it.
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break.
first.blank <- which(text == "")[1]
msg <- text[seq((first.blank + 1), length(text), by = 1)]
close(con)
return(paste(msg, collapse = "\\\n"))
}
msg <- get.msg(test)
msg
get.msg <- function(path) {
# This function will be used in conjunction with an anonymous function and sapply
# shortly. First, the funciton opens a connection to each file under the "read as text"
# connection. Then it uses ReadLines and stores it into a vector. The 'msg' vector
# is a subset of 'text' vector which is the actual email portion. The 'msg' vector
# is built by finding the first blank line in 'text', and getting each line after
# it. This is because each file is formatted as a blank line separating address informatino
# and the actual email sent. Finally, the connection is closed and the function returns
# a single element vector with the entire email content in it.
con <- file(path, encoding = "latin1")
text <- readLines(con)
# The message always begins after the first full line break.
first.blank <- which(text == "")[1]
msg <- text[seq((first.blank + 1), length(text), by = 1)]
close(con)
return(paste(msg, collapse = " "))
}
msg <- get.msg(spam.docs[1])
msg
msg.tdm <- make.tdm(msg)
msg.tdm
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.freq
as.matrix(msg.tdm)
all.easy
classify.email <- function(path, training.df, prior = 0.5, d = 1e-6) {
msg <- sapply(path, get.msg)
msg.tdm <- make.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
msg.match <- intersect(names(msg.freq), training.df$term)
if (length(msg.match) < 1) {
return(prior * d ^ (length(msg.freq)))
} else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * d ^ (length(msg.freq) - length(msg.match)))
}
}
